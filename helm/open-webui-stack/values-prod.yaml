# =============================================================================
# Production Values for Open WebUI Stack on GKE
# =============================================================================
# Cluster: demo-cluster (europe-west4-a)
# Project: soev-ai-001
# =============================================================================

# -----------------------------------------------------------------------------
# Global settings
# -----------------------------------------------------------------------------
global:
  storageClass: "standard-rwo"
  imagePullSecrets:
    - ghcr-secret

# -----------------------------------------------------------------------------
# Open WebUI Configuration Overrides
# -----------------------------------------------------------------------------
openWebui:
  config:
    # Admin bootstrap
    adminEmail: "lex@gradient-ds.com"
    adminName: "Lex"

    # CORS - update to match your domain
    corsAllowOrigin: "https://demo.soev.ai"

    # LLM Provider model filtering (per-connection, doesn't affect workspace agents)
    # This replaces MODEL_WHITELIST which blocked workspace agents
    openaiApiConfigs:
      "0":
        enable: true
        model_ids:
          - "openai/gpt-oss-120b"

    # OpenTelemetry Configuration - sends telemetry to observability stack
    telemetry:
      otel:
        enabled: true
        traces: true
        metrics: true
        logs: true
        endpoint: "http://alloy.observability.svc:4317"
        serviceName: "open-webui-prod"
        insecure: true
        resourceAttributes: "deployment.environment=production,k8s.cluster.name=demo-cluster"
        tenantId: "soev"  # For enterprise deployments, use "enterprise-{customer}"

# -----------------------------------------------------------------------------
# Ingress - nginx with cert-manager
# -----------------------------------------------------------------------------
ingress:
  enabled: true
  className: nginx
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/proxy-body-size: "100m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-http-version: "1.1"
    nginx.ingress.kubernetes.io/proxy-buffering: "off"
  hosts:
    - host: demo.soev.ai
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: open-webui-tls
      hosts:
        - demo.soev.ai

# -----------------------------------------------------------------------------
# Crawl4AI - Increase resources for better scraping performance
# -----------------------------------------------------------------------------
crawl4ai:
  resources:
    requests:
      memory: "4Gi"
      cpu: "1000m"
    limits:
      memory: "16Gi"
      cpu: "4000m"

# -----------------------------------------------------------------------------
# External Secrets Operator - Fetch secrets from GCP Secret Manager
# -----------------------------------------------------------------------------
externalSecrets:
  enabled: true
  gcpProject: "soev-ai-001"
  refreshInterval: "1h"
  # Using SA key since Workload Identity is not enabled on cluster
  gcpCredentialsSecret:
    name: gcp-secret-manager-credentials
    key: secret-access-credentials
    namespace: external-secrets

# -----------------------------------------------------------------------------
# Secrets - Only used when externalSecrets.enabled=false
# -----------------------------------------------------------------------------
# secrets:
#   webuiSecretKey: ""      # Generate: openssl rand -hex 32
#   adminPassword: ""       # Your admin password
#   openaiApiKey: ""        # HuggingFace or OpenAI key
#   ragOpenaiApiKey: ""     # OpenAI key for embeddings
#   postgresPassword: ""    # Generate: openssl rand -hex 32
#   searxngSecretKey: ""    # Generate: openssl rand -hex 16
