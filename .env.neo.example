# ============================================================
# NEO NL Open WebUI Configuration
# ============================================================
# Copy this file to .env.neo and fill in the values
# Usage: docker compose -f docker-compose.neo.yaml --env-file .env.neo up -d

# ------------------------------------------------------------
# DEPLOYMENT
# ------------------------------------------------------------

# Docker image tag (main, latest, or specific version)
WEBUI_DOCKER_TAG=main

# Port to expose Open WebUI on (default: 3000)
OPEN_WEBUI_PORT=3000

# Secret key for session encryption
# Generate with: openssl rand -hex 32
# Leave empty for auto-generation (stored in container volume)
WEBUI_SECRET_KEY=

# ------------------------------------------------------------
# LOCALE & BRANDING
# ------------------------------------------------------------

# Default interface language (nl-NL for Dutch)
DEFAULT_LOCALE=nl-NL

# ------------------------------------------------------------
# AUTHENTICATION & ACCESS
# ------------------------------------------------------------

# Enable authentication (required)
WEBUI_AUTH=true

# Disable public signup - only admin can create users
ENABLE_SIGNUP=false

# Show login form (needed for username/password auth)
ENABLE_LOGIN_FORM=true

# Allow first user to register as admin (required when ENABLE_SIGNUP=false)
ENABLE_INITIAL_ADMIN_SIGNUP=true

# Default role for new users created by admin: pending, user, or admin
DEFAULT_USER_ROLE=user

# ------------------------------------------------------------
# LLM PROVIDERS
# ------------------------------------------------------------

# Disable Ollama (we use cloud APIs only)
ENABLE_OLLAMA_API=false

# Hugging Face OpenAI-compatible endpoint
# Get token from: https://huggingface.co/settings/tokens
# Create a fine-grained token with "Make calls to Inference Providers" permission
OPENAI_API_BASE_URL=https://api.openai.com/v1
# OPENAI_API_BASE_URL=https://router.huggingface.co/v1
OPENAI_API_KEY=hf_your-huggingface-token_or_openai_token

# Model to use: openai/gpt-oss-120b (or other HF-hosted models)
# Models are selected in the Open WebUI interface

# Note: Additional providers can be added later via:
# OPENAI_API_KEYS=hf_key;openai_key (semicolon-separated)
# OPENAI_API_BASE_URLS=https://router.huggingface.co/v1;https://api.openai.com/v1

# ------------------------------------------------------------
# VECTOR DATABASE (Weaviate)
# ------------------------------------------------------------

VECTOR_DB=weaviate
WEAVIATE_HTTP_HOST=localhost
# WEAVIATE_HTTP_HOST=weaviate
WEAVIATE_HTTP_PORT=8082
WEAVIATE_GRPC_PORT=50053

# ------------------------------------------------------------
# Application database (Postgres)
# ------------------------------------------------------------
DATABASE_TYPE=postgresql
DATABASE_USER=openwebui
DATABASE_PASSWORD=dev_password
# DATABASE_HOST=postgres
DATABASE_HOST=localhost
DATABASE_PORT=5433
DATABASE_NAME=openwebui

# ------------------------------------------------------------
# RAG EMBEDDINGS (OpenAI)
# ------------------------------------------------------------

# Use OpenAI for embeddings (separate from chat LLM)
RAG_EMBEDDING_ENGINE=openai
RAG_EMBEDDING_MODEL=text-embedding-3-small

# OpenAI API key for embeddings
# Get from: https://platform.openai.com/api-keys
# Note: This is SEPARATE from the Hugging Face key used for chat
RAG_OPENAI_API_KEY=sk-your-openai-api-key

# Optional: Custom OpenAI endpoint for embeddings
# RAG_OPENAI_API_BASE_URL=https://api.openai.com/v1

# Embedding batch size (number of texts per API call)
RAG_EMBEDDING_BATCH_SIZE=100

# Bypass admin model access control
BYPASS_MODEL_ACCESS_CONTROL=True

# ------------------------------------------------------------
# RAG RETRIEVAL SETTINGS
# ------------------------------------------------------------

# Number of document chunks to retrieve per query (after reranking)
RAG_TOP_K=3

# Minimum relevance score (0.0 = no filtering)
RAG_RELEVANCE_THRESHOLD=0.0

# Chunk size for document splitting (characters)
CHUNK_SIZE=1000

# Overlap between chunks (characters)
CHUNK_OVERLAP=100

# ------------------------------------------------------------
# RERANKING (External CrossEncoder)
# ------------------------------------------------------------
# Uses the reranker service from genai-utils/services/reranker
# Start with: cd genai-utils/services && docker compose up -d

# Enable external reranker service
RAG_RERANKING_ENGINE=external
RAG_EXTERNAL_RERANKER_URL=http://reranker:8000/v1/rerank
RAG_EXTERNAL_RERANKER_API_KEY=

# Enable hybrid search (required for reranking to work)
ENABLE_RAG_HYBRID_SEARCH=true

# Number of results to keep after reranking (before RAG_TOP_K filter)
RAG_TOP_K_RERANKER=5

# ------------------------------------------------------------
# FILE UPLOAD SETTINGS
# ------------------------------------------------------------

# Maximum file size in bytes (default: no limit)
# RAG_FILE_MAX_SIZE=52428800  # 50MB

# Maximum number of files per upload (default: no limit)
# RAG_FILE_MAX_COUNT=10

# Allowed file extensions (comma-separated, empty = all)
# RAG_ALLOWED_FILE_EXTENSIONS=.pdf,.txt,.md,.docx

# ------------------------------------------------------------
# ADMIN USER (for automated bootstrap)
# ------------------------------------------------------------
# These are used by scripts/pipes/bootstrap_functions.py
# to automatically create admin user and register functions on startup
# only matters when working with pipes
OPENWEBUI_ADMIN_EMAIL=
OPENWEBUI_ADMIN_PASSWORD=
OPENWEBUI_ADMIN_NAME=


#----------------------------------------------------------
#EXTERNAL DOCUMENT LOADER/PARSER (genai-utils)
#----------------------------------------------------------
CONTENT_EXTRACTION_ENGINE = external
EXTERNAL_DOCUMENT_LOADER_URL=http://localhost:6006
EXTERNAL_DOCUMENT_LOADER_API_KEY=your-api-key


#----------------------------------------------------------
#EXTERNAL AGENTS (genai-utils)
#----------------------------------------------------------
EXTERNAL_AGENTS_REPO=
EXTERNAL_AGENTS_PACKAGE=agents
EXTERNAL_AGENTS_LIST=neo_nl_multiagent_pipe
EXTERNAL_AGENTS_AUTO_UPDATE=true


#----------------------------------------------------------
#RAG DOCUMENT FILTER 
#----------------------------------------------------------
ENABLE_RAG_FILTER_UI=true
PUBLIC_RAG_API_BASE_URL=http://localhost:3535 #(custom_API_server from genai-utils)
PUBLIC_RAG_API_KEY=your-dev-api-key-here


